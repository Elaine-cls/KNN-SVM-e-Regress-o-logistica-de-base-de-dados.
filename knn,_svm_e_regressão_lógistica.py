# -*- coding: utf-8 -*-
"""Knn, SVM e regressão lógistica.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r3CskVpneYhQyzu3dVbXlpdzs-w37iPg
"""

#Importando as bibliotecas
import time
import sklearn
import warnings
import numpy as np # algebra linear
import pandas as pd # processamento de dados
import seaborn as sns # Plotar a matriz de confusão como um HeatMap
from sklearn import tree
from sklearn import metrics
from sklearn.svm import SVC
import matplotlib.pyplot as plt
from sklearn import preprocessing
from imblearn.under_sampling import NearMiss
from sklearn.preprocessing import RobustScaler
from sklearn.tree import DecisionTreeClassifier #importando classificação por árvore de decisão
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier as KNN #importando classificador knn e métrica F1score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

warnings.filterwarnings("ignore")

# configurar o estilo dos gráficos com o Seaborn
sns.set_style('dark')

"""**Análise estátistica dos dados**"""

#importando o Dataset
data = pd.read_csv("hcvdat0.csv")

#Printando o Dataset
print('Quantidade de instâncias: {}\nQuantidade de atributos: {}\n'.format(len(data), len(data.columns)))
data[0:7]
data

#forma dos dados
data.shape

#primeiras 5 linhas dos dados
data.head()

# Checando o tipo dos dados
data.dtypes

#Checando valores faltantes nos dados
data.isnull().sum()

#quantidade de valores duplicados para todos os atributos
print('Valores duplicados:', data.duplicated())

x = data['Category'].value_counts() #cálculo das quantidades dos tipos do atributo label
x/len(data)  #cáculo das quantidades em relação ao conjunto completo (entre 0 e 1)

#gráfico de boxplot de outliers
np.random.seed(1234)
dataf = pd.DataFrame(np.random.randn(10000, 13),
                  columns=['Category', 'Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT'])
boxplot = dataf.boxplot(column=['Category', 'Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT'], grid=False, rot=45, fontsize=15, figsize = (15,7))

#mapa de correlação
corr = data.corr()
corr.style.background_gradient(cmap='coolwarm')

#gerando uma amostra aleatória com 4 elementos
data.loc[data['Category'] == "3=Cirrhosis"].sample(n=4, random_state =2)

# Verificando detalhes estatísticos do dataset
data.describe()

data['Category'].value_counts()

# Visualização dos dados
glass_classes = data['Category'].unique()
values = data['Category'].value_counts()

plt.bar(glass_classes, values)
plt.title('Categorias de doadores')
plt.xlabel('Classes')
plt.ylabel('Contador de Exemplos')
plt.show()

#Verificação de registros úncios no dataset
def distribuicao (data):
    '''
    Esta função exibirá a quantidade de registros únicos para cada coluna
    existente no dataset
    
    dataframe -> Histogram
    '''
    # Calculando valores unicos para cada label: num_unique_labels
    num_unique_labels = data.apply(pd.Series.nunique)

    # plotando valores
    num_unique_labels.plot( kind='bar')
    
    # Nomeando os eixos
    plt.xlabel('Campos')
    plt.ylabel('Número de Registros únicos')
    plt.title('Distribuição de dados únicos do DataSet')
    
    # Exibindo gráfico
    plt.show()

distribuicao(data)

#Visualizando a distribuição das classes
#Mostra a quantidade de registros de cada uma das classes.
#Mostra de forma gráfica
e = pd.value_counts(data['Category']) [0]
p = pd.value_counts(data['Category']) [1]
a = pd.value_counts(data['Category']) [2]
b = pd.value_counts(data['Category']) [3]
c = pd.value_counts(data['Category']) [4]

print("Tamanho dos dados: ")
tam = len(data)

print('0: ',e)
print('1: ',p )
print('2: ',a )
print('3: ',b )
print('4: ',c )

pie = pd.DataFrame([['0',e],['1',p], ['2',a], ['3',b], ['4',c]],columns=['Tipo' , 'Quantidade'])


def pie_chart(data,col1,col2,title): 
    labels = {'0':0,'1':1, '2':2, '3':3, '4':4}
    sizes = data[col2]
    colors = ['#B0E0E6', '#D8BFD8', '#FFE4C4', '#F5F5DC', '#FF7F50']

    plt.pie(sizes, labels=labels, colors=colors,
                autopct='%1.1f%%', shadow=True, startangle=140, labeldistance =1.2)
    plt.title( title )
    
    plt.axis('equal')
    plt.show()

print("\n")
pie_chart(pie,'Tipo' , 'Quantidade','Distribuição Percentual dos Rótulos de Classificação')


plt.bar(pie.Tipo,pie.Quantidade, color = ['#000080', '#D2691E', '#008000', '#B22222', '#8B008B'])
print("\n")
plt.title("Distribuição dos Rótulos de Classificação")
plt.xlabel("Tipo de Classificação")
plt.ylabel('Quantidade de Registros')
plt.show()

"""**Pré-Processamento de dados**"""

#exclui a coluna Unnamed: 0
data = data.drop(columns=['Unnamed: 0'])

#primeiras 5 linhas dos dados
data.head()

#subtitui os elementos faltosos pela mediana
"""median = data['ALB'].median()
data['ALB'].fillna(median, inplace = True) 
data"""

#subtitui os elementos faltosos pela mediana
"""median = data['ALT'].median()
data['ALT'].fillna(median, inplace = True) 
data"""

#subtitui os elementos faltosos pela mediana
"""median = data['PROT'].median()
data['PROT'].fillna(median, inplace = True) 
data"""

#elimina todas as linhas com dados ausentes
data = data.dropna(how ='any') 
data

#quantidade de valores faltantes para todos os atributos
print('Valores faltantes:', data.isnull().sum())

#transforma atributos qualitativos em quantitativos
le = preprocessing.LabelEncoder() 
for column in data.columns:
    if data[column].dtypes == 'object':
        data[column] = le.fit_transform(data[column])
        
print(data)

#Separando as categorias em doador e não doador
ids_suspect = data[data['Category'] == 1].index.values #pega os índices de todas as instâncias da classificadas como 1
subset = data.iloc[ids_suspect] #atribui todas essas instâncias a um novo dataframe (substet)
subset

#deletando coluna 'Category' do subset
subset.drop('Category', inplace = True, axis = 1) 
subset.head()

#removendo as instâncias que foram pro subset do dataframe original
df_remove = data.loc[(data['Category'] == 1)] 
data = data.drop(df_remove.index)
print('\nQuantidade de instâncias totais agora é: ', data.shape)
data['Category'].value_counts()

data['Category'] = data['Category'].replace([0], '1')
data['Category'] = data['Category'].replace([4, 2, 3], '0') #substituindo por 0, todas as classes que são 4, 2 ou 3
data['Category'].value_counts()

#Visualizando a distribuição das classes
#Mostra a quantidade de registros de cada uma das classes.
#Mostra de forma gráfica
e = pd.value_counts(data['Category']) [0]
p = pd.value_counts(data['Category']) [1]

print("Tamanho dos dados: ")
tam = len(data)

print('1: ',e)
print('0: ',p )

pie = pd.DataFrame([['1',e],['0',p]],columns=['Tipo' , 'Quantidade'])


def pie_chart(data,col1,col2,title): 
    labels = {'1':1,'0':0}
    sizes = data[col2]
    colors = ['#B0E0E6', '#D8BFD8']

    plt.pie(sizes, labels=labels, colors=colors,
                autopct='%1.1f%%', shadow=True, startangle=140, labeldistance =1.2)
    plt.title( title )
    
    plt.axis('equal')
    plt.show()

print("\n")
pie_chart(pie,'Tipo' , 'Quantidade','Distribuição Percentual dos Rótulos de Classificação')


plt.bar(pie.Tipo,pie.Quantidade, color = ['#B0E0E6', '#D8BFD8'])
print("\n")
plt.title("Distribuição dos Rótulos de Classificação")
plt.xlabel("Tipo de Classificação")
plt.ylabel('Quantidade de Registros')
plt.show()

def plot_corr(corr):
    #cortaremos a metade de cima pois é o espelho da metade de baixo
    mask = np.zeros_like(corr, dtype=np.bool)
    mask[np.triu_indices_from(mask, 1)] = True
    sns.heatmap(corr, mask=mask, cmap='RdBu', square=True, linewidths=0.5)
#calculando a correlação
corr = data.corr() 
corr.style.background_gradient(cmap='coolwarm').set_precision(2)

#Tratamento de Outliers
#normalizando com RobustScaler
data_normalizado = RobustScaler().fit_transform(data.copy())
data_normalizado

#calculando a correlação dos dados normalizados com RobustScaler
corrRobust = pd.DataFrame(data_normalizado).corr()
corrRobust.style.background_gradient(cmap='coolwarm').set_precision(2)

#visualizando dados depois de normalizados
data_normalizado= pd.DataFrame(data_normalizado)
data_normalizado

#normalizando subset
subset = RobustScaler().fit_transform(subset)
subset

"""**####################### Classificações para os dados originais ######################**

Preparando os dados para as classificações
"""

#Definindo a amostra e o alvo
X = data.iloc[:, 1:].values #definindo variáveis que serão as amostras - todas menos 'Categoria'
y = data.iloc[:, 0].values #definindo variável que será o alvo - 'Categoria'
y = y.astype('int') #definindo o alvo como int

#criando o trem e o conjunto de validação
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, stratify=y, random_state = 70)

# forma de variáveis ​​independentes e dependentes
X.shape, y.shape

#forma do conjunto de treinamento
X_train.shape, y_train.shape

#forma do conjunto de teste
X_test.shape,y_test.shape

"""**Árvore de decisão**"""

#ajustando o modelo
dt_model = DecisionTreeClassifier(random_state=10)

dt_model.fit(X_train, y_train)

#verificar a pontuação do treinamento
dt_model.score(X_train, y_train)

#verificar a pontuação de validação
dt_model.score(X_test, y_test)

#previsões no conjunto de validação
dt_predict=dt_model.predict(X_test)
dt_predict

accuracy_score(y_test,dt_predict)

#Encontrando max_depth ideal
train_accuracy = []
validation_accuracy = []
for depth in range(1,15):
    dt_model = DecisionTreeClassifier(max_depth=depth, random_state=6)
    dt_model.fit(X_train, y_train)
    train_accuracy.append(dt_model.score(X_train, y_train))
    validation_accuracy.append(dt_model.score(X_test, y_test))

frame = pd.DataFrame({'max_depth':range(1,15), 'train_acc':train_accuracy, 'test_acc':validation_accuracy})
frame.head()

plt.figure(figsize=(14,6))
plt.plot(frame['max_depth'], frame['train_acc'], marker='o')
plt.plot(frame['max_depth'], frame['test_acc'], marker='o')
plt.xlabel('Profundidade da árvore')
plt.ylabel('performance')
plt.legend(['train_acc','test_acc'])

# máx. a profundidade continua aumentando até o máximo. a profundidade é 9 depois que permanece constante.
dt_model = DecisionTreeClassifier(max_depth=9, max_leaf_nodes=35, random_state=10)
#ajustando o modelo
dt_model.fit(X_train, y_train)

#Pontuação de treinamento
dt_model.score(X_train, y_train)

#pontuação da validação
dt_model.score(X_test, y_test)

dt_predict1=dt_model.predict(X_test)
dt_predict1

#Acurácia
accuracy_score(y_test,dt_predict1)

# Gera a matriz de confusão do modelo
cnf_matrix = metrics.confusion_matrix(y_test,dt_predict1)
cnf_matrix

# Plota a matriz de confusão como um HeatMap
class_names=[0,1] # Name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria um heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

# Exibe um relatório abrangente do modelo DT
print(metrics.classification_report(y, dt_model.predict(X),zero_division=1))

#Gera árvore do modelo
plt.figure(figsize = (20,10))
tree.plot_tree(dt_model);

"""**K-Nearest Neighbour - KNN**"""

# importante mencionar que n_neighs = 5, não é um valor múltiplo de nossa quantidade de recursos
clf = KNN(n_neighbors = 5)

# Ajustando o modelo
clf.fit(X_train, y_train)

#Acurácia
predict_type_n = clf.predict(X_test)
accuracy_score(y_test,predict_type_n)

#encontrando o valor k ideal
train_accuracy = []
validation_accuracy = []
for i in range(1,15):
    clf = KNN(n_neighbors = i)
    clf.fit(X_train, y_train)
    train_accuracy.append(clf.score(X_train, y_train))
    validation_accuracy.append(clf.score(X_test, y_test))

frame = pd.DataFrame({'n_neighbors':range(1,15), 'train_acc':train_accuracy, 'valid_acc':validation_accuracy})
frame.head(10)

#Gráfico do KNN
plt.figure(figsize=(14,6))
plt.plot(frame['n_neighbors'], frame['train_acc'], marker='o')
plt.plot(frame['n_neighbors'], frame['valid_acc'], marker='o')
plt.xlabel('Valor do K')
plt.ylabel('performance')
plt.legend(['train_acc','valid_acc'])

#Acurácia
clf = KNN(n_neighbors = 8)
clf.fit(X_train, y_train)
#Pontuação do treinamento
clf.score(X_train, y_train)

predict_type_n_2 = clf.predict(X_test)
predict_type_n_2

#Acurácia final
accuracy_score(y_test,predict_type_n_2)

# Gera a Matriz de confusão do Modelo
cnf_matrix_1 = metrics.confusion_matrix(y_test,predict_type_n_2)
cnf_matrix_1

# Plota a matriz de confusão com um HeatMap
class_names=[0,1] # nome das classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria um heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_1), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

# Exibe um relatório abrangente do modelo KNN
print(metrics.classification_report(y, clf.predict(X),zero_division=1))

"""**SVM**"""

clf_1=SVC(kernel='linear')
clf_1.fit(X_train, y_train)

clf_1.get_params()

y_pred = clf_1.predict(X_test)

# Precisão do modelo: com que frequência o classificador está correto?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Gera a matriz de confusão do modelo
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

class_names=[0,1] # nome das classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

# Exibe um relatório abrangente do modelo SVC
print(metrics.classification_report(y, clf_1.predict(X),zero_division=1))

"""**Regressão logística**"""

#Instância o classificador
lr = LogisticRegression() 
#Treinando o algoritmo
lr.fit(X_train, y_train)

#Coloca as classificações na variável y_pred
y_pred = lr.predict(X_test) 
#Checa a acurácia do modelo
accuracy_score(y_test, y_pred)

#Recall
print (classification_report(y_test, y_pred))

#Matriz de confusão
print (pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predito'], margins=True))

# Plot the Confusion Matrix as a HeatMap
class_names=[0,1] # Name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

"""**############################## Classificações para os dados com tratamentos de outiliers ###############################**

Preparando os dados para as classificações
"""

#fazendo o mesmo, mas para os dados normalizados agora
X_normalizado = data_normalizado.iloc[:, 1:].values
y_normalizado = data_normalizado.iloc[:, 0].values

#Separando os dados em 70% para treino e 30% para teste
X_train, X_test, y_train, y_test = train_test_split(X_normalizado, y_normalizado,  test_size = 0.3, random_state = 42)

# forma de variáveis ​​independentes e dependentes
X_normalizado.shape, y_normalizado.shape

#forma do conjunto de treinamento
X_train.shape, y_train.shape

#forma do conjunto de teste
X_test.shape,y_test.shape

"""**Árvore de decisão**"""

#ajustando o modelo
dt_model = DecisionTreeClassifier(random_state=10)

dt_model.fit(X_train, y_train)

#verificar a pontuação do treinamento
dt_model.score(X_train, y_train)

#verificar a pontuação de validação
dt_model.score(X_test, y_test)

#previsões no conjunto de validação
dt_predict=dt_model.predict(X_test)
dt_predict

accuracy_score(y_test,dt_predict)

#Encontrando max_depth ideal
train_accuracy = []
validation_accuracy = []
for depth in range(1,15):
    dt_model = DecisionTreeClassifier(max_depth=depth, random_state=6)
    dt_model.fit(X_train, y_train)
    train_accuracy.append(dt_model.score(X_train, y_train))
    validation_accuracy.append(dt_model.score(X_test, y_test))

frame = pd.DataFrame({'max_depth':range(1,15), 'train_acc':train_accuracy, 'test_acc':validation_accuracy})
frame.head()

plt.figure(figsize=(14,6))
plt.plot(frame['max_depth'], frame['train_acc'], marker='o')
plt.plot(frame['max_depth'], frame['test_acc'], marker='o')
plt.xlabel('Profundidade da árvore')
plt.ylabel('performance')
plt.legend(['train_acc','test_acc'])

# máx. a profundidade continua aumentando até o máximo. a profundidade é 9 depois que permanece constante.
dt_model = DecisionTreeClassifier(max_depth=9, max_leaf_nodes=35, random_state=10)
#ajustando o modelo
dt_model.fit(X_train, y_train)

#Pontuação de treinamento
dt_model.score(X_train, y_train)

#pontuação da validação
dt_model.score(X_test, y_test)

dt_predict1=dt_model.predict(X_test)
dt_predict1

#Acurácia
accuracy_score(y_test,dt_predict1)

# Gera a matriz de confusão do modelo
cnf_matrix = metrics.confusion_matrix(y_test,dt_predict1)
cnf_matrix

# Plota a matriz de confusão como um HeatMap
class_names=[0,1] # Name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria um heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

# Exibe um relatório abrangente do modelo DT
print(metrics.classification_report(y_normalizado, dt_model.predict(X_normalizado),zero_division=1))

#Gera árvore do modelo
plt.figure(figsize = (20,10))
tree.plot_tree(dt_model);

"""**Knn**"""

# importante mencionar que n_neighs = 5, não é um valor múltiplo de nossa quantidade de recursos
clf = KNN(n_neighbors = 5)

# Ajustando o modelo
clf.fit(X_train, y_train)

#Acurácia
predict_type_n = clf.predict(X_test)
accuracy_score(y_test,predict_type_n)

#encontrando o valor k ideal
train_accuracy = []
validation_accuracy = []
for i in range(1,15):
    clf = KNN(n_neighbors = i)
    clf.fit(X_train, y_train)
    train_accuracy.append(clf.score(X_train, y_train))
    validation_accuracy.append(clf.score(X_test, y_test))

frame = pd.DataFrame({'n_neighbors':range(1,15), 'train_acc':train_accuracy, 'valid_acc':validation_accuracy})
frame.head(10)

#Gráfico do KNN
plt.figure(figsize=(14,6))
plt.plot(frame['n_neighbors'], frame['train_acc'], marker='o')
plt.plot(frame['n_neighbors'], frame['valid_acc'], marker='o')
plt.xlabel('Valor do K')
plt.ylabel('performance')
plt.legend(['train_acc','valid_acc'])

#Acurácia
clf = KNN(n_neighbors = 8)
clf.fit(X_train, y_train)
#Pontuação do treinamento
clf.score(X_train, y_train)

predict_type_n_2 = clf.predict(X_test)
predict_type_n_2

#Acurácia final
accuracy_score(y_test,predict_type_n_2)

# Gera a Matriz de confusão do Modelo
cnf_matrix_1 = metrics.confusion_matrix(y_test,predict_type_n_2)
cnf_matrix_1

# Plota a matriz de confusão com um HeatMap
class_names=[0,1] # nome das classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria um heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_1), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

# Exibe um relatório abrangente do modelo KNN
print(metrics.classification_report(y_normalizado, clf.predict(X_normalizado),zero_division=1))

"""**SVM**"""

clf_1=SVC(kernel='linear')
clf_1.fit(X_train, y_train)

#Checando os paramêtros
clf_1.get_params()

y_pred = clf_1.predict(X_test)

# Precisão do modelo: com que frequência o classificador está correto?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Gera a matriz de confusão do modelo
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

class_names=[0,1] # nome das classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

# Exibe um relatório abrangente do modelo SVC
print(metrics.classification_report(y_normalizado, clf_1.predict(X_normalizado),zero_division=1))

"""**Regressão logistíca**"""

#Instância o classificador
lr = LogisticRegression() 
#Treinando o algoritmo
lr.fit(X_train, y_train)

#Coloca as classificações na variável y_pred
y_pred = lr.predict(X_test) 
#Checa a acurácia do modelo
accuracy_score(y_test, y_pred)

#Recall
print (classification_report(y_test, y_pred))

#Matriz de confusão
print (pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predito'], margins=True))

# Plot the Confusion Matrix as a HeatMap
class_names=[0,1] # Name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

"""**############################## Classificações para os dados originais balanceados ###############################**

**Balanceamento dos dados originais**
"""

nr = NearMiss()
X, y = nr.fit_sample(X, y)
 
#ver o balanceamento das classes
print(pd.Series(y).value_counts())
 
#plotar a nova distribuição de classes
sns.countplot(y);

"""Preparando os dados para as classificações"""

#criando o trem e o conjunto de validação
X_train, X_test, y_train, y_test = train_test_split(X,y,  test_size = 0.3, stratify=y, random_state = 42)

# forma de variáveis ​​independentes e dependentes
X.shape, y.shape

#forma do conjunto de treinamento
X_train.shape, y_train.shape

#forma do conjunto de teste
X_test.shape,y_test.shape

"""**Árvores de decisão**"""

#ajustando o modelo
dt_model = DecisionTreeClassifier(random_state=10)

dt_model.fit(X_train, y_train)

#verificar a pontuação do treinamento
dt_model.score(X_train, y_train)

#verificar a pontuação de validação
dt_model.score(X_test, y_test)

#previsões no conjunto de validação
dt_predict=dt_model.predict(X_test)
dt_predict

accuracy_score(y_test,dt_predict)

#Encontrando max_depth ideal
train_accuracy = []
validation_accuracy = []
for depth in range(1,15):
    dt_model = DecisionTreeClassifier(max_depth=depth, random_state=6)
    dt_model.fit(X_train, y_train)
    train_accuracy.append(dt_model.score(X_train, y_train))
    validation_accuracy.append(dt_model.score(X_test, y_test))

frame = pd.DataFrame({'max_depth':range(1,15), 'train_acc':train_accuracy, 'test_acc':validation_accuracy})
frame.head()

plt.figure(figsize=(14,6))
plt.plot(frame['max_depth'], frame['train_acc'], marker='o')
plt.plot(frame['max_depth'], frame['test_acc'], marker='o')
plt.xlabel('Profundidade da árvore')
plt.ylabel('performance')
plt.legend(['train_acc','test_acc'])

# máx. a profundidade continua aumentando até o máximo. a profundidade é 9 depois que permanece constante.
dt_model = DecisionTreeClassifier(max_depth=9, max_leaf_nodes=35, random_state=10)
#ajustando o modelo
dt_model.fit(X_train, y_train)

#Pontuação de treinamento
dt_model.score(X_train, y_train)

#pontuação da validação
dt_model.score(X_test, y_test)

dt_predict1=dt_model.predict(X_test)
dt_predict1

#Acurácia
accuracy_score(y_test,dt_predict1)

# Gera a matriz de confusão do modelo
cnf_matrix = metrics.confusion_matrix(y_test,dt_predict1)
cnf_matrix

# Plota a matriz de confusão como um HeatMap
class_names=[0,1] # Name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria um heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

# Exibe um relatório abrangente do modelo DT
print(metrics.classification_report(y, dt_model.predict(X),zero_division=1))

#Gera árvore do modelo
plt.figure(figsize = (20,10))
tree.plot_tree(dt_model);

"""**KNN**"""

# importante mencionar que n_neighs = 5, não é um valor múltiplo de nossa quantidade de recursos
clf = KNN(n_neighbors = 5)

# Ajustando o modelo
clf.fit(X_train, y_train)

#Acurácia
predict_type_n = clf.predict(X_test)
accuracy_score(y_test,predict_type_n)

#encontrando o valor k ideal
train_accuracy = []
validation_accuracy = []
for i in range(1,15):
    clf = KNN(n_neighbors = i)
    clf.fit(X_train, y_train)
    train_accuracy.append(clf.score(X_train, y_train))
    validation_accuracy.append(clf.score(X_test, y_test))

frame = pd.DataFrame({'n_neighbors':range(1,15), 'train_acc':train_accuracy, 'valid_acc':validation_accuracy})
frame.head(10)

#Gráfico do KNN
plt.figure(figsize=(14,6))
plt.plot(frame['n_neighbors'], frame['train_acc'], marker='o')
plt.plot(frame['n_neighbors'], frame['valid_acc'], marker='o')
plt.xlabel('Valor do K')
plt.ylabel('performance')
plt.legend(['train_acc','valid_acc'])

#Acurácia
clf = KNN(n_neighbors = 8)
clf.fit(X_train, y_train)
#Pontuação do treinamento
clf.score(X_train, y_train)

predict_type_n_2 = clf.predict(X_test)
predict_type_n_2

#Acurácia final
accuracy_score(y_test,predict_type_n_2)

# Gera a Matriz de confusão do Modelo
cnf_matrix_1 = metrics.confusion_matrix(y_test,predict_type_n_2)
cnf_matrix_1

# Plota a matriz de confusão com um HeatMap
class_names=[0,1] # nome das classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria um heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_1), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

# Exibe um relatório abrangente do modelo KNN
print(metrics.classification_report(y, clf.predict(X),zero_division=1))

"""**SVM**"""

clf_1=SVC(kernel='linear')
clf_1.fit(X_train, y_train)

clf_1.get_params()

y_pred = clf_1.predict(X_test)

# Precisão do modelo: com que frequência o classificador está correto?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Gera a matriz de confusão do modelo
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

class_names=[0,1] # nome das classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

# Exibe um relatório abrangente do modelo SVC
print(metrics.classification_report(y, clf_1.predict(X),zero_division=1))

"""**Regressão logistíca**"""

#Instância o classificador
lr = LogisticRegression() 
#Treinando o algoritmo
lr.fit(X_train, y_train)

#Coloca as classificações na variável y_pred
y_pred = lr.predict(X_test) 
#Checa a acurácia do modelo
accuracy_score(y_test, y_pred)

#Recall
print (classification_report(y_test, y_pred))

#Matriz de confusão
print (pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predito'], margins=True))

# Plot the Confusion Matrix as a HeatMap
class_names=[0,1] # Name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

"""**############################## Classificações para os dados tratados balanceados ###############################**

**Balanceamento dos dados tratados**
"""

X_normalizado, y_normalizado = nr.fit_sample(X_normalizado, y_normalizado)
 
# ver o balanceamento das classes
print(pd.Series(y_normalizado).value_counts())
 
# plotar a nova distribuição de classes
sns.countplot(y_normalizado);

"""Preparando os dados para as classificações"""

#criando o trem e o conjunto de validação
X_train, X_test, y_train, y_test = train_test_split(X_normalizado,y_normalizado, test_size = 0.3, stratify=y, random_state = 42)

# forma de variáveis ​​independentes e dependentes
X_normalizado.shape, y_normalizado.shape

#forma do conjunto de treinamento
X_train.shape, y_train.shape

#forma do conjunto de teste
X_test.shape,y_test.shape

"""**Árvore de Decisão**"""

#ajustando o modelo
dt_model = DecisionTreeClassifier(random_state=10)

dt_model.fit(X_train, y_train)

#verificar a pontuação do treinamento
dt_model.score(X_train, y_train)

#verificar a pontuação de validação
dt_model.score(X_test, y_test)

#previsões no conjunto de validação
dt_predict=dt_model.predict(X_test)
dt_predict

accuracy_score(y_test,dt_predict)

#Encontrando max_depth ideal
train_accuracy = []
validation_accuracy = []
for depth in range(1,15):
    dt_model = DecisionTreeClassifier(max_depth=depth, random_state=6)
    dt_model.fit(X_train, y_train)
    train_accuracy.append(dt_model.score(X_train, y_train))
    validation_accuracy.append(dt_model.score(X_test, y_test))

frame = pd.DataFrame({'max_depth':range(1,15), 'train_acc':train_accuracy, 'test_acc':validation_accuracy})
frame.head()

plt.figure(figsize=(14,6))
plt.plot(frame['max_depth'], frame['train_acc'], marker='o')
plt.plot(frame['max_depth'], frame['test_acc'], marker='o')
plt.xlabel('Profundidade da árvore')
plt.ylabel('performance')
plt.legend(['train_acc','test_acc'])

# máx. a profundidade continua aumentando até o máximo. a profundidade é 9 depois que permanece constante.
dt_model = DecisionTreeClassifier(max_depth=9, max_leaf_nodes=35, random_state=10)
#ajustando o modelo
dt_model.fit(X_train, y_train)

#Pontuação de treinamento
dt_model.score(X_train, y_train)

#pontuação da validação
dt_model.score(X_test, y_test)

dt_predict1=dt_model.predict(X_test)
dt_predict1

#Acurácia
accuracy_score(y_test,dt_predict1)

# Gera a matriz de confusão do modelo
cnf_matrix = metrics.confusion_matrix(y_test,dt_predict1)
cnf_matrix

# Plota a matriz de confusão como um HeatMap
class_names=[0,1] # Name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria um heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

# Exibe um relatório abrangente do modelo DT
print(metrics.classification_report(y_normalizado, dt_model.predict(X_normalizado),zero_division=1))

#Gera árvore do modelo
plt.figure(figsize = (20,10))
tree.plot_tree(dt_model);

"""**KNN**"""

# importante mencionar que n_neighs = 5, não é um valor múltiplo de nossa quantidade de recursos
clf = KNN(n_neighbors = 5)

# Ajustando o modelo
clf.fit(X_train, y_train)

#Acurácia
predict_type_n = clf.predict(X_test)
accuracy_score(y_test,predict_type_n)

#encontrando o valor k ideal
train_accuracy = []
validation_accuracy = []
for i in range(1,15):
    clf = KNN(n_neighbors = i)
    clf.fit(X_train, y_train)
    train_accuracy.append(clf.score(X_train, y_train))
    validation_accuracy.append(clf.score(X_test, y_test))

frame = pd.DataFrame({'n_neighbors':range(1,15), 'train_acc':train_accuracy, 'valid_acc':validation_accuracy})
frame.head(10)

#Gráfico do KNN
plt.figure(figsize=(14,6))
plt.plot(frame['n_neighbors'], frame['train_acc'], marker='o')
plt.plot(frame['n_neighbors'], frame['valid_acc'], marker='o')
plt.xlabel('Valor do K')
plt.ylabel('performance')
plt.legend(['train_acc','valid_acc'])

#Acurácia
clf = KNN(n_neighbors = 8)
clf.fit(X_train, y_train)
#Pontuação do treinamento
clf.score(X_train, y_train)

predict_type_n_2 = clf.predict(X_test)
predict_type_n_2

#Acurácia final
accuracy_score(y_test,predict_type_n_2)

# Gera a Matriz de confusão do Modelo
cnf_matrix_1 = metrics.confusion_matrix(y_test,predict_type_n_2)
cnf_matrix_1

# Plota a matriz de confusão com um HeatMap
class_names=[0,1] # nome das classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria um heatmap
sns.heatmap(pd.DataFrame(cnf_matrix_1), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

# Exibe um relatório abrangente do modelo KNN
print(metrics.classification_report(y_normalizado, clf.predict(X_normalizado),zero_division=1))

"""**SVM**"""

clf_1=SVC(kernel='linear')
clf_1.fit(X_train, y_train)

clf_1.get_params()

y_pred = clf_1.predict(X_test)

# Precisão do modelo: com que frequência o classificador está correto?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Gera a matriz de confusão do modelo
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

class_names=[0,1] # nome das classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

# Exibe um relatório abrangente do modelo SVC
print(metrics.classification_report(y_normalizado, clf_1.predict(X_normalizado),zero_division=1))

"""**Regressão logistíca**"""

#Instância o classificador
lr = LogisticRegression() 
#Treinando o algoritmo
lr.fit(X_train, y_train)

#Coloca as classificações na variável y_pred
y_pred = lr.predict(X_test) 
#Checa a acurácia do modelo
accuracy_score(y_test, y_pred)

#Recall
print (classification_report(y_test, y_pred))

#Matriz de confusão
print (pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predito'], margins=True))

# Plot the Confusion Matrix as a HeatMap
class_names=[0,1] # Name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# cria heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Matriz de confusão', y=1.1)
plt.ylabel('label atual')
plt.xlabel('label previsto')

"""**##########################################################################################################**

***Questão 02. Base de dados wine***

A análise exploratória dessa base de dados foi feita utilizando Clustering K-Means com técnicas de seleção K, e avisualização de clusters foi feita usando PCA.
"""

#Analise de dados e préprocessamento:
import pandas as pd
pd.set_option('display.max_columns', None)
pd.options.display.float_format = "{:.2f}".format
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm import tqdm
#Cluster k-means
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import sklearn.cluster as cluster
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
#Cluster Hierarquico
from sklearn.cluster import AgglomerativeClustering
from scipy.cluster.hierarchy import linkage, dendrogram

"""**Análise estatísticas dos dados**"""

#Lê e transforma o conjunto de dados em um DataFrame do pandas a partir de um arquivo csv
#importando o Dataset
data = pd.read_csv("wine.csv")

#Printando o Dataset
print('Quantidade de instâncias: {}\nQuantidade de atributos: {}\n'.format(len(data), len(data.columns)))
data[0:7]
data

#forma dos dados
data.shape

"""Análise Exploratória de Dados (EDA)
Verificar o cabeçalho dos dados, como podemos ver, todos os dados são numéricos: não há valores categóricos
"""

#primeiras 5 linhas dos dados
data.head()

# Checando o tipo dos dados
data.dtypes

"""Procurando algumas informações estatísticas sobre cada recurso, podemos ver que os recursos têm escalas muito diferentes"""

data.describe()

"""Verificando a assimetria de nosso conjunto de dados.

Um dado normalmente distribuído tem uma assimetria próxima de zero.

Assimetria maior que zero significa que há mais peso no lado esquerdo dos dados.

Por outro lado, assimetria menor que 0 significa que há mais peso no lado direito dos dados.


  ![Captura de tela de 2020-12-07 03-16-40.png](data:image/png;base64,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)
"""

data.skew()

"""Traçando o histograma de cada variável numérica (neste caso, todos os recursos), a ideia principal aqui é visualizar a distribuição dos dados para cada recurso. Este método pode trazer insights rápidos como:
*   Verificar o tipo de distribuição de cada recurso;
*   Verificar a simetria dos dados;
*   Verificar a frequência dos recursos;
*   Identificar outliers;

"""

#Plotando historiogramas dos dados
sns.set(style='white',font_scale=1.3, rc={'figure.figsize':(20,20)})
ax=data.hist(bins=20,color='red' )

"""Para reforçar nossos insights sobre a simetria dos dados e seus outliers, podemos traçar alguns boxplots:
"Um gráfico de caixa é um método para representar graficamente grupos de dados numéricos através de seus quartis. A caixa se estende dos valores dos quartil de Q1 a Q3 dos dados, com uma linha na mediana (Q2). Os bigodes se estendem das bordas da caixa para mostrar o intervalo dos dados. A posição dos bigodes é definida por padrão para 1,5 * IQR (IQR = Q3 - Q1) das bordas da caixa. Os pontos outlier são aqueles após o final dos bigodes. "
"""

#Boxplot dos outliers
data.plot( kind = 'box', subplots = True, layout = (4,4), sharex = False, sharey = False,color='black')
plt.show()

#Verificando se existem valores nulos, como podemos ver nosso conjunto de dados não tem valores nulos
data.isnull().sum().sort_values(ascending=False).head()

"""**Processamento dos dados**

Vamos usar um algoritmo K-means, pois ele usa a distância como a principal métrica para alocar os dados em seu respectivo cluster, precisamos ter cuidado com a escala, porque podemos dar mais "relevância" aos recursos de grande escala e apesar os de baixa escala
Para evitar isso, podemos usar vários métodos de escalonamento, neste caso vou Satandardizar os dados: ter uma média 0 e uma variância unitária.
"""

std_scaler = StandardScaler()
data_cluster=data.copy()
data_cluster[data_cluster.columns]=std_scaler.fit_transform(data_cluster)

#Verifica se a padronização foi feita corretamente, procurando média = 0 e std = 1
data_cluster.describe()

#Mapa de correlação
corr = data_cluster.corr()
plt.figure(figsize=(12,12))
sns.heatmap(corr, linewidths=.5, cmap='viridis')

"""Como estamos lidando com um conjunto de dados multidimensional, estarei usando uma Análise de Componente Principal para reduzir sua dimensão e torná-lo "plotável" em um plano cartesiano. Lembrando que provavelmente perderemos algumas informações / variações neste processo, mas é apenas para fins de visualização."""

pca_2 = PCA(2)
pca_2_result = pca_2.fit_transform(data_cluster)

print ('Cumulative variance explained by 2 principal components: {:.2%}'.format(np.sum(pca_2.explained_variance_ratio_)))

sns.set(style='white', rc={'figure.figsize':(9,6)},font_scale=1.1)

plt.scatter(x=pca_2_result[:, 0], y=pca_2_result[:, 1], color='red',lw=0.1)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('Data represented by the 2 strongest principal components',fontweight='bold')
plt.show()

"""**Implementação do modelo**

Estamos usando o algoritmo K-means, para escolher K (número de clusters) foram combinadas duas técnicas: o Silhouette Score e o K-means Inertia (com análise de cotovelo).

Primeiro, vamos calcular todas as inércias. Basicamente, quanto menor a inércia, melhor será o agrupamento.
"""

#Calculo de todas as inércias
inertia = []
for i in tqdm(range(2,10)):
    kmeans = cluster.KMeans(n_clusters=i,
               init='k-means++',
               n_init=15,
               max_iter=500,
               random_state=17)
    kmeans.fit(data_cluster)
    inertia.append(kmeans.inertia_)

"""A seguir, calcularemos a pontuação da silhueta. Aqui, quanto maior a pontuação, melhor será o agrupamento"""

#Pontuação da silhueta
silhouette = {}
for i in tqdm(range(2,10)):
    kmeans = cluster.KMeans(n_clusters=i,
               init='k-means++',
               n_init=15,
               max_iter=500,
               random_state=17)
    kmeans.fit(data_cluster)
    silhouette[i] = silhouette_score(data_cluster, kmeans.labels_, metric='euclidean')

sns.set(style='white',font_scale=1.1, rc={'figure.figsize':(12,5)})

plt.subplot(1, 2, 1)

plt.plot(range(2,len(inertia)+2), inertia, marker='o',lw=2,ms=8,color='red')
plt.xlabel('Number of clusters')
plt.title('K-means Inertia',fontweight='bold')
plt.grid(True)

plt.subplot(1, 2, 2)

plt.bar(range(len(silhouette)), list(silhouette.values()), align='center',color= 'red',width=0.5)
plt.xticks(range(len(silhouette)), list(silhouette.keys()))
plt.grid()
plt.title('Silhouette Score',fontweight='bold')
plt.xlabel('Number of Clusters')


plt.show()

"""Como podemos ver, em K = 3 todas as métricas indicam que é o melhor número de clusters. Então, vamos usá-lo"""

kmeans = cluster.KMeans(n_clusters=3,random_state=17,init='k-means++')
kmeans_labels = kmeans.fit_predict(data_cluster)

centroids = kmeans.cluster_centers_
centroids_pca = pca_2.transform(centroids)

pd.Series(kmeans_labels).value_counts()

"""Aqui, podemos visualizar cada distribuição de recursos de acordo com cada cluster, nesta etapa podemos definir algumas características para cada grupo"""

data2=data.copy()
data2['Cluster']=kmeans_labels

aux=data2.columns.tolist()
aux[0:len(aux)-1]

for cluster in aux[0:len(aux)-1]:
    grid= sns.FacetGrid(data2, col='Cluster')
    grid.map(plt.hist, cluster,color='red')

"""Outra abordagem é olhar para cada centróide do cluster para definir as características do cluster"""

centroids_data=pd.DataFrame(data=std_scaler.inverse_transform(centroids), columns=data.columns)
centroids_data.head()

#if we want to add label to data We do cluster data(x and y)
kmeans2 = KMeans(n_clusters = 2)
clusters = kmeans2.fit_predict(data_cluster)
data["label"] = clusters

#We look how many whether true our clusters
data_ac = pd.read_csv("wine.csv")
data_ac["Alcohol"] = [0 if each == "Abnormal" else 1 for each in data_ac["Alcohol"]]
data_ac_class = data_ac["Alcohol"]
predict_class = data["label"]
print("accuracy is : {}".format(100 - np.mean(np.abs(data_ac_class - predict_class)*100)))
kmeans_accuracy = int(100 - np.mean(np.abs(data_ac_class - predict_class)*100))

"""**Visualização do cluster do PCA**"""

sns.set(style='white', rc={'figure.figsize':(9,6)},font_scale=1.1)

plt.scatter(x=pca_2_result[:, 0], y=pca_2_result[:, 1], c=kmeans_labels, cmap='autumn')
plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1],
            marker='x', s=169, linewidths=3,
            color='black', zorder=10,lw=3)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('Clustered Data (PCA visualization)',fontweight='bold')
plt.show()

"""**############################################Método hierárquico##############################################**"""

merg = linkage(data_cluster,method="ward")
dendrogram(merg,leaf_rotation = 90)
plt.xlabel("data points")
plt.ylabel("euclidean distance")
plt.show()

hiyerartical_cluster = AgglomerativeClustering(n_clusters = 2,affinity= "euclidean",linkage = "ward")
cluster = hiyerartical_cluster.fit_predict(data_cluster)

data["label_hc"] = cluster

plt.scatter(x = data[data.label_hc == 0].Alcohol,y = data[data.label_hc == 0].Proline , color = "yellow")
plt.scatter(x = data[data.label_hc == 1].Alcohol,y = data[data.label_hc == 1].Proline , color = "blue")

#Let's we calculate accuracy.
#data_ac["class"] = [0 if each == "Abnormal" else 1 for each in data_ac["class"]]
#data_ac_class = data_ac["class"]
#predict_class = data["label"]
print("accuracy is : {}".format(100 - np.mean(np.abs(data_ac_class - data["label_hc"])*100)))
hc_accuracy = int(100 - np.mean(np.abs(data_ac_class - data["label_hc"])*100))

#We compare our model in graph
fig = plt.figure(figsize = (15,5))

plt.subplot(1, 3, 2)
plt.scatter(x = data[data.label == 0].Alcohol,y = data[data.label == 0].Proline, color = "yellow")
plt.scatter(x = data[data.label == 1].Alcohol,y = data[data.label == 1].Proline , color = "red")
plt.title("kmeans") 

plt.subplot(1, 3, 3)
plt.scatter(x = data[data.label_hc == 0].Alcohol,y = data[data.label_hc == 0].Proline , color = "yellow")
plt.scatter(x = data[data.label_hc == 1].Alcohol,y = data[data.label_hc == 1].Proline , color = "red")
plt.title("hierarchical")

plt.show()

#We have hc_accuracy and kmeans_accuracy
list1 = ["hc","kmeans"]
list2 = [hc_accuracy,kmeans_accuracy]
list3 = [100 - hc_accuracy,100 - kmeans_accuracy]
dictionary = {"name":list1,"value":list2,"hundred":list3}
data = pd.DataFrame(dictionary)

#!pip install chart-studio

"""import chart_studio.plotly as py
import plotly.graph_objs as go
from plotly.offline import init_notebook_mode, iplot
init_notebook_mode(connected=True)
trace1 = go.Bar(
x = data.name,
y = data.value,
name="accuracy",
marker = {"color":"rgba(111,23,155,0.5)"},
text=data.name
)
trace2 = go.Bar(
x = data.name,
y = data.hundred,
name="mistake",
marker = {"color":"rgba(47,69,187)"},
)
fig_data = [trace1,trace2]
layout = go.Layout(barmode = "relative")
fig = go.Figure(data = fig_data, layout = layout)
iplot(fig)"""